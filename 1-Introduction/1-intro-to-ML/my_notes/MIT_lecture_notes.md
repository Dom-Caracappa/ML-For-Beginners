# MIT Lecture from Lesson 1

## What is Machine Learning
**"Field of study that gives computers the ability to learn without being explicity programmed." - Arther Samuel (1959)**

- He cracked AI Checkers
- Invented **Alpha-Beta Pruning**

### Traditional Programing
I give the computer data and then a program of steps to manipulate that data into my desired output.

### Machine Learning
I give the computer output, examples of what I want, then I want the computer to produce a program that I can use to solve my problem.


### Ways to Learn

#### Declarative Knowledge
- Memorization
    - Accumulation of individual facts.
    - Limited by
        a. Time to observe facts
        b. Memory space

#### Imperative Knowledge
- Generalization
    - Deduce new facts from old facts.
    - Limited by accuracy of the deduction process.
        a. Essentially a *predictive* activity.
        b. Assumes that what is past is prologue. 

#### Inference 
Machine learning aims to create algorithums to infer about new data.
- Give system some training data.
- Write some code to infer process information from that data.
- Use inference to make predictions about previously unseen data: test data

### Variations on paradigm of Inference that can be used in broad ways
- Supervised: All pieces of the training data is labeled, we know what KIND of thing it is. How can I find a rule that would predict the label with unseen input BASED off those examples.

- Unsupervised: No pieces of training data is labeled and I must try and discover the natural patterns that could allow me to predict either "how many labels are there (sometimes we define labels and sometimes not)" or what is the "best grouping I can find".


## Classification Model
**Using labeled data to define classes**






## Clustering Model